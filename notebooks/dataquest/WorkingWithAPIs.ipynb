{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f94adc8-44a6-45fb-b2f0-520552dc25da",
   "metadata": {},
   "source": [
    "# Working With APIs\n",
    "\n",
    "Corresponds to DataQuest course. Further down, we dive deeper into the GitHub REST API, using `ghapi` for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e1110-8c47-4684-a60c-a074fe7c9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d73f8-523e-4690-a976-42d761578254",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://api.open-notify.org/astros.json\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d0673-e76a-4b8c-af37-b4354c008b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_astros_response(response):\n",
    "    if response.status_code == 200:\n",
    "        res_dict = response.json()\n",
    "        print(f\"There are currently {res_dict['number']} people in space:\")\n",
    "        astros = [f\"{e['name']} on the {e['craft']}\" for e in res_dict['people']]\n",
    "        print(\"\\n\".join(astros))\n",
    "    else:\n",
    "        print(f\"Call to astros.json resulted in status_code = {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f2fca-1abb-4421-a0f5-7ffa4f0726e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_astros_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db46899-4d7d-4451-90d5-3478244d989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fe846-eea4-406a-98b3-d7c84d603489",
   "metadata": {},
   "source": [
    "This is how parameters are passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e61c98-eb76-4b17-9c3e-69164db7f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the latitude and longitude of New York City.\n",
    "parameters = {\"lat\": 40.71, \"lon\": -74}\n",
    "\n",
    "# Make a get request with the parameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "\n",
    "print(response.url)\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821d5f7-738f-40a8-8f20-dda2dbed89fe",
   "metadata": {},
   "source": [
    "## GitHub API\n",
    "\n",
    "Next, we look at the GitHub API.\n",
    "\n",
    "First, we consider GET requests. If successful, these return the status code 200. Codes from 400 or 500 denote errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90842f90-5f3c-412e-9ab1-b1aaaba1d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of headers containing our Authorization header.\n",
    "# Note: This is a temporary token, with restricted access only\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "headers = {\"Authorization\": f\"token {token}\"}\n",
    "\n",
    "# Make a GET request to the GitHub API with our headers.\n",
    "response = requests.get(\"https://api.github.com/users/mseeger/repos\", headers=headers)\n",
    "\n",
    "for e in response.json():\n",
    "    print(f\"{e['html_url']}: {e['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978596d-edcf-4f16-9210-7673ba8d284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eed22d-ddbd-43ef-9b50-035f5521dca6",
   "metadata": {},
   "source": [
    "Let us list all repositories in `awslabs`. This requires pagination. We use the best practice, scanning the 'Link' string in the header for the `rel=\"next\"` entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be39042-c71a-4d14-b1cb-a2e2ad7d78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_extract(response, pages, st_entry=None):\n",
    "    json_data = response.json()\n",
    "    names = [e['name'] for e in json_data]\n",
    "    if st_entry is None:\n",
    "        try:\n",
    "            pos = names.index(\"syne-tune\")\n",
    "            st_entry = json_data[pos]\n",
    "        except ValueError:\n",
    "            pass\n",
    "    new_pages = pages + [names]\n",
    "    return new_pages, st_entry\n",
    "\n",
    "endpoint = \"https://api.github.com/orgs/awslabs/repos\"\n",
    "regex = r\"(?<=<)([\\S]*)(?=>; rel=\\\"next\\\")\"\n",
    "pages = []\n",
    "st_entry = None\n",
    "st_not_yet_found = True\n",
    "num_pages = 0\n",
    "\n",
    "while endpoint is not None:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Request for page {num_pages + 1} failed! status_code = {response.status_code}\")\n",
    "        break\n",
    "    pages, st_entry = collect_and_extract(response, pages, st_entry)\n",
    "    num_pages += 1\n",
    "    print(f\"Obtained page {num_pages}\")\n",
    "    if st_not_yet_found and st_entry is not None:\n",
    "        print(\"Found syne-tune\")\n",
    "        st_not_yet_found = False\n",
    "    endpoint = None\n",
    "    links = response.headers.get('Link')\n",
    "    if links:\n",
    "        m = re.search(regex, links)\n",
    "        if m:\n",
    "            endpoint = m.group(1)\n",
    "\n",
    "num_repos = sum(len(names) for names in pages)\n",
    "print(f\"\\nFound {num_repos} repositories:\")\n",
    "for names in pages:\n",
    "    print(\"\\n\".join(names))\n",
    "\n",
    "if st_entry:\n",
    "    print(\"\\nFound syne-tune:\\n\" + str(st_entry))\n",
    "else:\n",
    "    print(\"\\nDid not find syne-tune!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f87034-e883-42dd-971a-d72d4eaaad90",
   "metadata": {},
   "source": [
    "A POST request sends data to an API, or is used to create a new object on the server. If successful, a POST request returns status code 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b018f79-94bc-45f4-9c4d-54893e9d5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create a new (empty) repository\n",
    "\n",
    "# Note: If we run this again, we obtain error code 422 for\n",
    "# \"Validation failed, or the endpoint has been spammed\". In our case,\n",
    "# this means that the repo already exists.\n",
    "\n",
    "payload = {\"name\": \"small-test-repo\"}\n",
    "response = requests.post(\n",
    "    \"https://api.github.com/user/repos\", headers=headers, json=payload\n",
    ")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c508ff-f5c3-4717-9a6c-225226a83416",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e797817-bd98-4a20-b83c-2fb9d732bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us delete the repo again\n",
    "\n",
    "response = requests.delete(\n",
    "    \"https://api.github.com/repos/mseeger/small-test-repo\", headers=headers\n",
    ")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15580e20-bd2b-4bfc-8790-a1594c035075",
   "metadata": {},
   "source": [
    "We are not authorized to delete the repository under the token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81ddc1-834e-4c94-b2b0-81d8283c5c32",
   "metadata": {},
   "source": [
    "A PUT or PATCH request is used to modify an object on the server. Typically, PATCH is just changing some attributes, while PUT needs the full object as input, which replaces the one on the server. If successful, these requests return status code 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967a765-4d26-43f2-9d7b-7eed7e773330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us modify the new repo by assigning a description\n",
    "\n",
    "payload = {\"name\": \"small-test-repo\", \"description\": \"This repo is just for testing API calls\"}\n",
    "response = requests.patch(\n",
    "    \"https://api.github.com/repos/mseeger/small-test-repo\", headers=headers, json=payload\n",
    ")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55999bc-1332-45b3-beea-68e569992f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b75b10-bd1b-488e-8c52-b39b301665c3",
   "metadata": {},
   "source": [
    "## Search and Download Files from Repository Using ghapi\n",
    "\n",
    "Let us do something more complicated. First, we use the GitHub search API to find files which contain a certain string. Next, we download these files.\n",
    "\n",
    "We make our life easier by using https://ghapi.fast.ai/, which provides a Pythonic API to the GitHub REST API, dealing with lots of details in the background, such as composing headers or pagination. It offers full tab completion in the notebook, as well as links to the GitHub API documentation.\n",
    "\n",
    "**Note**: As seen on https://github.com/fastai/ghapi, `ghapi` does not seem to be actively maintained anymore. The last release was in 2022, and there are more than 40 open issues. Maybe it is better to look for alternatives?\n",
    "\n",
    "Alternatives are listed here: https://docs.github.com/en/rest/using-the-rest-api/libraries-for-the-rest-api?apiVersion=2022-11-28#python. PyGithub has 6500 stars, but comes with GPL 3 licence (ghapi is Apache 2). All in all, it was probably heavily used at `fastai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28807c4-e43e-4948-a675-ec1501d02095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghapi.all import GhApi\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "api = GhApi(owner=\"awslabs\", repo=\"syne-tune\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0129d6-475f-4107-aa51-709ed7a41500",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ccf75-9c48-41e1-9838-4d0f4723b5d9",
   "metadata": {},
   "source": [
    "The search retrieves all files containing the search term. We can also obtain the fragments where the term is found, along with the spans. Below, we print the fragments, highlighting the spans in red.\n",
    "\n",
    "Note: If the search terms appears more than twice in a fragment, only the first two appearances are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a64cc-44b7-44dd-bee5-ff48019b3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using ANSI escape sequences in order to highlight the spans in red:\n",
    "# https://www.geeksforgeeks.org/print-colors-python-terminal/\n",
    "def highlight_spans_in_red(fragment, spans):\n",
    "    start_seq = \"\\033[91m\"\n",
    "    end_seq = \"\\033[00m\"\n",
    "    spans = [[0, 0]] + [s['indices'] for s in spans]\n",
    "    parts = []\n",
    "    for prev, curr in zip(spans[:-1], spans[1:]):\n",
    "        parts.extend([fragment[prev[1]:curr[0]], start_seq, fragment[curr[0]:curr[1]], end_seq])\n",
    "    parts.append(fragment[spans[-1][1]:])\n",
    "    return \"\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e5feb-79b3-4e2b-8ec0-278a2aaabf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We search for all Python files which contain the `search_term`\n",
    "from ghapi.page import paged\n",
    "\n",
    "# TODO: Can we enforce case-sensitivity?\n",
    "search_term = \"SimulatorBackend\"\n",
    "query = f\"{search_term} in:file repo:awslabs/syne-tune extension:py language:python\"\n",
    "\n",
    "# We use \"text-match+json\" in the Accept header, in order to obtain details on where the\n",
    "# search term is matched in each file:\n",
    "# https://docs.github.com/en/rest/search/search?apiVersion=2022-11-28#text-match-metadata\n",
    "results = paged(\n",
    "    api.search.code,\n",
    "    q=query,\n",
    "    headers={'Accept': 'application/vnd.github.text-match+json'},\n",
    ")\n",
    "\n",
    "all_paths = []\n",
    "total_count = None\n",
    "count_so_far = 0\n",
    "\n",
    "for page in results:\n",
    "    if total_count is None:\n",
    "        total_count = int(page['total_count'])\n",
    "        print(f\"Found {total_count} matching files in total\")\n",
    "    for result in page['items']:\n",
    "        path = result['path']\n",
    "        print(f\"\\n[File: {path}]\")\n",
    "        num_found = 0\n",
    "        text_matches = result['text_matches']\n",
    "        num_frags = len(text_matches)\n",
    "        print(f\"{num_frags} fragment{'s' if num_frags > 1 else ''}:\")\n",
    "        for match in text_matches:\n",
    "            fragment = match['fragment']\n",
    "            spans = match['matches']\n",
    "            num_spans = len(spans)\n",
    "            num_found += num_spans\n",
    "            print(f\"--- [{num_spans}] ---\")\n",
    "            print(highlight_spans_in_red(fragment, spans))\n",
    "        print(\"-----------\")\n",
    "        all_paths.append((path, num_found))\n",
    "    num_results = len(page['items'])\n",
    "    count_so_far += num_results\n",
    "    # The iterator does not properly stop on its own\n",
    "    if count_so_far >= total_count or num_results == 0:\n",
    "        if count_so_far < total_count:\n",
    "            print(f\"Retrieved {count_so_far} of {total_count} results only, but page is empty\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b5973-55fb-40c8-852d-1bc04b6aa0bc",
   "metadata": {},
   "source": [
    "Note that the search does not seem to be case-sensitive. Let us now download all files containing the search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a071f84-6be9-471f-bb7b-c356d91ce146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "\n",
    "for path, num_matches in all_paths:\n",
    "    result = api.repos.get_content(path)\n",
    "    print(f\"\\n******** [{path}]: Found {num_matches} match{'es' if num_matches > 1 else ''} {'*' * 40}\\n\")\n",
    "    print(b64decode(result['content']).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63343d78-3ab2-43cd-9c2e-def6f7266306",
   "metadata": {},
   "source": [
    "Another cool project would be to search for and access pull requests:\n",
    "\n",
    "* Which files have been modified?\n",
    "* What are the diffs?\n",
    "\n",
    "This could be useful in order to obtain data about how certain issues have been fixed, which in turn could be used as \"instruction tuning\" data for an AI assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ea730-9d9a-4f5a-8d29-18c89d4164ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.pulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b44ce-98b4-4d8a-affa-a249fa157a25",
   "metadata": {},
   "source": [
    "Let us fetch information for pull request `717` in `syne-tune`. First, `pulls.get` returns the basic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f5aad-17fc-4234-a195-7ddded1136c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.pulls.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50012f1a-aa76-44ad-a966-a8aa00e8641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_kwargs = dict(\n",
    "    owner=\"awslabs\",\n",
    "    repo=\"syne-tune\",\n",
    "    pull_number=717,\n",
    ")\n",
    "\n",
    "response = api.pulls.get(**pr_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e801fa-1b2b-45c4-9991-c5266c9eb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted(response.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88b65f-312d-4994-9cc9-5807252b83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8388f-2f9e-479d-ada5-5bcaa2198942",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info = \"\"\"\n",
    "-----------------------------------------------------------\n",
    "{title} #{number}\n",
    "\n",
    "{body}\n",
    "-----------------------------------------------------------\n",
    "User posting PR:           {user}\n",
    "State:                     {state}\n",
    "Number of files changed:   {changed_files}\n",
    "Was merged:                {merged}\n",
    "Created at:                {created_at}\n",
    "Closed at:                 {closed_at}\n",
    "Merged at:                 {merged_at}\n",
    "Merged by:                 {merged_by}\n",
    "ID:                        {id}\n",
    "Base SHA:                  {base_sha}\n",
    "Merge Commit SHA:          {merge_commit_sha}\n",
    "Labels:                    {labels}\n",
    "Requested reviewers:       {requested_reviewers}\n",
    "Number of comments:        {comments}\n",
    "Number of review comments: {review_comments}\n",
    "\"\"\"\n",
    "\n",
    "direct_names = [\n",
    "    \"title\", \"number\", \"body\", \"state\", \"changed_files\", \"created_at\", \"closed_at\",\n",
    "    \"issue_url\", \"id\", \"merged\", \"merged_at\", \"requested_reviewers\", \"comments\",\n",
    "    \"review_comments\", \"merge_commit_sha\",\n",
    "]\n",
    "pr_info = {name: response[name] for name in direct_names}\n",
    "pr_info[\"labels\"] = [e[\"name\"] for e in response[\"labels\"]]\n",
    "pr_info[\"merged_by\"] = response[\"merged_by\"][\"login\"]\n",
    "pr_info[\"user\"] = response[\"user\"][\"login\"]\n",
    "pr_info[\"base_sha\"] = response[\"base\"][\"sha\"]\n",
    "\n",
    "print(basic_info.format(**pr_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf726fe-b98b-48f3-b3f3-42f70ee1aeec",
   "metadata": {},
   "source": [
    "The following information can have multiple parts, and needs to be fetched by separate API calls:\n",
    "\n",
    "* Files changed (and change patches)\n",
    "* Reviews, along with their comments linked to code parts\n",
    "\n",
    "Let us first look at reviews and their comments: `pulls.list_reviews`, `pulls.list_comments_for_review`. Note that `pulls.list_review_comments` provides a flat list of all review comments linked to code parts, but does not contain the summary comment for each review. Also, `pulls.get_review` returns the same information as `pulls.list_reviews`, but for one specific review only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fae0f-8b7a-4458-8340-f795c81d65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_per_review = \"\"\"\n",
    "[ REVIEW {id} ]\n",
    "{body}\n",
    "\n",
    "User:      {user}\n",
    "State:     {state}\n",
    "\"\"\"\n",
    "\n",
    "info_per_review_comment = \"\"\"\n",
    "[ COMMENT {id} ]\n",
    "{body}\n",
    "\n",
    "Path:       {path}\n",
    "Position:   {position}\n",
    "Diff hunk:\n",
    "{diff_hunk}\n",
    "\"\"\"\n",
    "\n",
    "# Note: Both API calls are paginated, but we are lazy here (there are only 3 reviews, and they have 0 or 1 comment each)\n",
    "response = api.pulls.list_reviews(**pr_kwargs)\n",
    "print(f\"Found {len(response)} reviews:\")\n",
    "for review in response:\n",
    "    review_id = review['id']\n",
    "    kwargs = {name: review[name] for name in [\"body\", \"id\", \"state\"]}\n",
    "    kwargs[\"user\"] = review[\"user\"][\"login\"]\n",
    "    print(info_per_review.format(**kwargs))\n",
    "    response2 = api.pulls.list_comments_for_review(**pr_kwargs, review_id=review_id)\n",
    "    for comment in response2:\n",
    "        kwargs = {name: comment[name] for name in [\"body\", \"id\", \"path\", \"position\", \"diff_hunk\"]}\n",
    "        print(info_per_review_comment.format(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f2f44-9c66-482a-b978-4247f5249e5b",
   "metadata": {},
   "source": [
    "Finally, we look at files changed: `pulls.list_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fd45c-a3bc-472e-9027-24fd4bc1613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_per_file = \"\"\"\n",
    "[ PATCH {filename} ]\n",
    "{patch}\n",
    "\n",
    "Additions: {additions}\n",
    "Deletions: {deletions}\n",
    "Changes:   {changes}\n",
    "\"\"\"\n",
    "\n",
    "# Note: The API call is paginated, but we are lazy here (there are only 9 files changed)\n",
    "response = api.pulls.list_files(**pr_kwargs)\n",
    "print(f\"Found {len(response)} files changed:\")\n",
    "for review in response:\n",
    "    kwargs = {name: review[name] for name in [\"filename\", \"patch\", \"additions\", \"deletions\", \"changes\"]}\n",
    "    print(info_per_file.format(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9aab8-5fab-443a-9da6-3ed34d6d189a",
   "metadata": {},
   "source": [
    "What does `list_commits` do?\n",
    "\n",
    "For this PR, there is one commit. It lists 'author', 'committer' (both 'mseeger'). Its SHA is 'afde70bfec901d64f9d2603893dacacf2b5945f2', which is not the same as the SHA for the merge commit. This is most likely the commit for which the PR was issued. There may be further commits for changes based on review comments, all of which are different from the final merge commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a5911-28c9-4d91-8058-d58e7accd92d",
   "metadata": {},
   "source": [
    "We would like to iterate over all PRs of a repository and filter them according to some criterion. We can use `pulls.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2f236-19be-48af-8500-3ab9d84a37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = api.pulls.list(**pr_kwargs, state=\"closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec038a5-1d64-4b03-963d-95c5c84bea07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a691612-d735-4a2f-a8b4-adce2dabd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(f\"{e['number']}: {e['title']} ({e['merged_at']})\" for e in response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738ee70-c162-4204-b3e6-88166a13b23d",
   "metadata": {},
   "source": [
    "Fields in entries returned by `pulls.list` useful for filtering:\n",
    "\n",
    "* `number`: Number of PR\n",
    "* `merged_at`: TS when PR was merged, or `None` if PR was not merged\n",
    "* `labels`: Labels assigned to the PR\n",
    "* `created_at`, `closed_at`: More TS\n",
    "* `user`: Who submitted the PR?\n",
    "* `title`: Title of PR\n",
    "\n",
    "Annoyingly, there is no information about the number of files changed, or the total number or size of changes. This needs `pulls.get` for every PR. All in all, we can use `pulls.list` for some first round of filtering (e.g., by timestamps; only PRs which were merged; by user; by labels assigned), and iterate over the remaining ones with `pulls.get` for a second round of filtering.\n",
    "\n",
    "These fields are returned by `pulls.get`, but not by `pulls.list`:\n",
    "\n",
    "* 'additions', 'deletions', 'changed_files': Total number of additions, deletions (lines), and changed files\n",
    "* 'comments', 'commits', 'review_comments': Number of comments, review comments, and commits\n",
    "* 'mergeable', 'mergeable_state', 'merged', 'merged_by': Note that `merged_at` is returned by `pulls.list`\n",
    "* 'maintainer_can_modify', 'rebaseable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63566fc3-a797-4a2a-aa95-91080869ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_list = set(response[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3110a-c718-4981-acbc-7dabf0c66a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = api.pulls.get(**pr_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100dd6af-63bb-47f6-a146-6cdbe77ffe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_get = set(response.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c3fd2-be1e-4652-aa7a-2add32a37004",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_get.difference(keys_for_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d407a-9943-4fe4-a891-fb360d5788f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_list.difference(keys_for_get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be4141-72e9-4c7f-b76a-0d09ad5af741",
   "metadata": {},
   "source": [
    "Finally, we'd like to explore searching for particular repositories or pull requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d6301-0ed5-4acd-b5a2-8f8b1f185d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5b6e5-b54a-4d67-99fd-29a0539d45ef",
   "metadata": {},
   "source": [
    "We can use `search.search_repos`. With `sort=\"stars\"` (and `order=\"desc\"`, the default), repos with the highest number of stars are returned first; with `sort=\"forks\"`, repos with the largest number of forks are returned first. The search query in `q` can have fields detailed here:\n",
    "\n",
    "https://docs.github.com/en/search-github/searching-on-github/searching-for-repositories.\n",
    "\n",
    "* `jquery in:name` matches repositories with \"jquery\" in the repository name. `jquery in:description`, `jquery in:readme`\n",
    "* `user: xyz`, `org: xyz`: Repos of this user or org\n",
    "* `size:<n`, `size:>n`, `size:<=n`, `size:>=n`, `size:n..m`: repos of size less than, more than, between. Numbers are in KB\n",
    "* `followers:>=n`, ...: Number of followers\n",
    "* `forks:>=n`, ...: Number of forks\n",
    "* `stars:>=n`, ...: Number of stars\n",
    "* `fork:true`: Include forks in search results\n",
    "* `language:python`: Repos with code in Python\n",
    "* `created:<YYYY-MM-DD`: Creation date\n",
    "* `pushed:>YYYY-MM-DD`: Pushed to date (can be used to filter out inactive repos)\n",
    "* `license:LICENSE_KEYWORD`: Repos with certain license\n",
    "* `is:public`: Only public repos (not private ones you have access to)\n",
    "\n",
    "This should be very useful to narrow down a search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33abd2-04ea-4cf2-b785-70ec5bc9c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"size:<50000 forks:>100 stars:>2000 language:python pushed:>2023-11-01 is:public\"\n",
    "\n",
    "respose = api.search.repos(q=query, sort=\"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2229392-f971-4383-9aaa-6f534601510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(respose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60640b4f-21a5-4119-8336-3d14cf788c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.recv_hdrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948a100-24fd-41fe-950f-774cf613b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1157e43-975b-4070-bb3e-c98347a77635",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(respose['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ec0ed-d7eb-4282-b858-d062ef8a978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "respose['items'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43884d3-d932-4cc1-9d99-718dcf48bcf4",
   "metadata": {},
   "source": [
    "## Reddit API\n",
    "\n",
    "Calls to the Reddit API need to be authenticated using `OAuth`. This seems challenging to setup. Would have to be done in order to be able to use the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59347f20-0ce1-4982-9e07-97a693062129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
